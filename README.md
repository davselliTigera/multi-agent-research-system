# ğŸ¤– Multi-Agent Research System

A distributed AI research system with **two implementation versions**: Custom REST API and standards-compliant A2A Protocol. Each agent is an independent microservice with specialized expertise, collaborating to conduct comprehensive research on any topic.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?logo=kubernetes&logoColor=white)](https://kubernetes.io/)
[![Python](https://img.shields.io/badge/Python-3.11-3776AB?logo=python&logoColor=white)](https://www.python.org/)

## ğŸ¯ Two Versions Available

This repository contains **two complete implementations**:

### **1. REST API Version** (Original)
- Custom REST endpoints
- Simpler architecture
- ~5-10% faster

### **2. A2A Protocol Version** (Standards-Compliant)
- Google's Agent-to-Agent protocol
- Standardized messages (`agent://` URIs)
- Capability discovery (`GET /capabilities`)

**Choose your version based on your needs!** See [REST-vs-A2A.md](docs/REST-vs-A2A.md) for detailed comparison.

## âœ¨ Features

- **ğŸ¯ Specialized AI Agents** - 5 independent agents with unique expertise
- **â˜¸ï¸ Kubernetes-Native** - Fully containerized, cloud-ready
- **ğŸ”„ Dual Protocols** - Choose REST or A2A
- **ğŸ“Š State Management** - Redis-backed shared state
- **ğŸ¨ Interactive UI** - Streamlit interface
- **ğŸ“ˆ Horizontal Scaling** - Scale agents independently
- **ğŸ” Real-time Monitoring** - Live agent activity tracking
- **ğŸ”„ Agent Reusability** - Use agents in other applications

## ğŸ—ï¸ Architecture

This system uses a **hub-and-spoke microservices architecture** where a central Coordinator orchestrates five specialized AI agents through Redis-based state management.

### Quick Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit  â”‚ â† User Interface
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Coordinator â”‚ â† Orchestration Hub
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â†’ Topic Refiner    (ğŸ¯ Port 8001)
       â”œâ”€â”€â†’ Question Architect (â“ Port 8002)
       â”œâ”€â”€â†’ Search Strategist  (ğŸ” Port 8003)
       â”œâ”€â”€â†’ Data Analyst       (ğŸ“Š Port 8004)
       â””â”€â”€â†’ Report Writer      (ğŸ“ Port 8005)
             â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Redis   â”‚ â† Shared State
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Points**:
- âœ… Agents communicate via Redis (shared state)
- âœ… No direct agent-to-agent communication
- âœ… Coordinator orchestrates the sequential workflow
- âœ… Each agent is independently scalable

> **ğŸ“– For detailed architecture documentation, see [docs/architecture.md](docs/architecture.md)**  
> This includes message flow diagrams, code references, state management details, and architectural patterns.

### The Agent Team

Each agent is a specialized microservice with its own LLM instance, personality, and expertise:

#### ğŸ¯ **Dr. Topic Refiner** (Port 8001)
- **Role**: Research Topic Specialist
- **Expertise**: Clarifying research objectives and scoping studies
- **Temperature**: 0.5 (More focused and consistent)

#### â“ **Prof. Question Architect** (Port 8002)
- **Role**: Research Question Designer
- **Expertise**: Formulating precise, investigable research questions
- **Temperature**: 0.7 (Balanced creativity)

#### ğŸ” **Agent Search Strategist** (Port 8003)
- **Role**: Information Retrieval Specialist
- **Expertise**: Designing search strategies and executing queries
- **Temperature**: 0.3 (Very focused and precise)

#### ğŸ“Š **Dr. Data Analyst** (Port 8004)
- **Role**: Research Data Analyst
- **Expertise**: Extracting insights and identifying patterns
- **Temperature**: 0.4 (Analytical and focused)

#### ğŸ“ **Dr. Report Writer** (Port 8005)
- **Role**: Research Report Specialist
- **Expertise**: Synthesizing findings into clear, structured reports
- **Temperature**: 0.6 (Moderately creative for readability)

### Research Workflow

The Coordinator orchestrates agents in this sequence:

```
1. ğŸ¯ Topic Refiner     â†’ Refines raw user input into focused topic
                          â†“ (writes to Redis)
2. â“ Question Architect â†’ Generates 3 research questions
                          â†“ (writes to Redis)
3. ğŸ” Search Strategist  â†’ Executes web searches
                          â†“ (writes to Redis)
4. ğŸ“Š Data Analyst      â†’ Analyzes results, extracts findings
                          â†“ (writes to Redis)
                          
   [Decision: Continue iteration or finalize?]
   
   If continue â†’ Loop back to step 2
   If finalize â†’ Proceed to step 5
   
5. ğŸ“ Report Writer     â†’ Generates final research report
                          â†“ (writes to Redis)
6. âœ… Complete          â†’ User receives report
```

> **ğŸ’¡ Note**: Agents don't call each other directly. The Coordinator:
> 1. Calls Agent â†’ Agent writes results to Redis
> 2. Reads Redis â†’ Calls next Agent
> 3. Repeat until workflow completes

This hub-and-spoke pattern provides:
- **Simplicity**: Clear, predictable workflow
- **Scalability**: Each agent scales independently
- **Debuggability**: Centralized orchestration and logging
- **Fault Isolation**: Agent failures don't cascade

### Key Architectural Features

#### ğŸ”— **Inter-Service Communication**
- **Synchronous**: HTTP/REST API calls between coordinator and agents
- **Asynchronous**: Background task processing for long-running research
- **State Management**: Redis for shared state across all services
- **Message Format**: 
  - REST: Custom JSON payload
  - A2A: Standardized `@type` based messages

#### ğŸ”„ **Workflow Orchestration**
- **Dynamic Routing**: Coordinator decides when to continue or finalize research
- **Iterative Refinement**: Loops back to generate more questions based on findings
- **Quality Assessment**: Data Analyst calculates quality scores to determine completion
- **Error Handling**: Graceful degradation with detailed error propagation

#### ğŸ“¦ **Microservices Benefits**
- **Independent Scaling**: Scale search agents separately from other agents
- **Fault Isolation**: One agent failure doesn't crash the entire system
- **Technology Flexibility**: Each agent can use different libraries/versions
- **Deployment Independence**: Update agents without system-wide restarts
- **Resource Optimization**: Each agent has tailored CPU/memory allocation

#### ğŸšï¸ **Temperature Settings**
Each agent uses specific temperature settings for optimal performance:
- **0.2-0.3**: Deterministic (Search Strategist)
- **0.4-0.5**: Analytical (Data Analyst, Topic Refiner)
- **0.6-0.7**: Balanced creativity (Report Writer, Question Architect)

## ğŸš€ Quick Start

### Prerequisites

- **Kubernetes Cluster** - Either:
  - **[Kind](https://kind.sigs.k8s.io/)** (Kubernetes in Docker) for local development
  - **[kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/)** for production-ready clusters
- **[kubectl](https://kubernetes.io/docs/tasks/tools/)** - Kubernetes CLI
- **[Docker](https://docs.docker.com/get-docker/)** - Container runtime
- **Google API Key** - For Gemini LLM ([Get one here](https://makersuite.google.com/app/apikey))

### Installation

#### Option 1: Kind Cluster (Development)

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/multi-agent-research-system.git
   cd multi-agent-research-system
   ```

2. **Create a Kind cluster**
   ```bash
   kind create cluster --name research-cluster
   kubectl cluster-info --context kind-research-cluster
   ```

3. **Set your Google API key**
   ```bash
   export GOOGLE_API_KEY="your-google-api-key-here"
   ```

4. **Deploy your chosen version**

   **REST API Version:**
   ```bash
   chmod +x scripts/deploy-to-kind.sh
   ./scripts/deploy-to-kind.sh
   ```

   **A2A Protocol Version:**
   ```bash
   chmod +x scripts/deploy-a2a-to-kind.sh
   ./scripts/deploy-a2a-to-kind.sh
   ```

5. **Access the application**
   ```bash
   kubectl port-forward service/streamlit-service 8501:80
   # Open http://localhost:8501
   ```

#### Option 2: kubeadm Cluster with Local Registry

For kubeadm clusters using a local registry (e.g., `lynx.tigera.local`):

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/multi-agent-research-system.git
   cd multi-agent-research-system
   ```

2. **Ensure your local registry is accessible**
   ```bash
   # Verify registry connectivity
   curl -X GET http://lynx.tigera.local/v2/_catalog
   
   # Ensure kubeconfig is set
   kubectl cluster-info
   ```

3. **Set your Google API key**
   ```bash
   export GOOGLE_API_KEY="your-google-api-key-here"
   ```

4. **Deploy A2A Protocol version**
   ```bash
   chmod +x scripts/deploy-a2a-to-kubeadm.sh
   ./scripts/deploy-a2a-to-kubeadm.sh
   ```

   This script will:
   - Build all container images
   - Tag them for your local registry (`lynx.tigera.local/multi-agent-research`)
   - Push images to the registry
   - Deploy to your kubeadm cluster

5. **Access the application**
   ```bash
   kubectl port-forward service/streamlit-service 8501:80
   # Open http://localhost:8501
   ```

> **Note:** The kubeadm deployment script uses the local registry at `lynx.tigera.local`. If you're using a different registry, modify the `REGISTRY` variable in `scripts/deploy-a2a-to-kubeadm.sh` accordingly.

## ğŸ“– Usage

### Conducting Research

1. Open the Streamlit UI at `http://localhost:8501`
2. Enter your research topic (e.g., "Benefits of microservices architecture")
3. Adjust max iterations (1-5) in the sidebar
4. Click "ğŸš€ Deploy Agents"
5. Watch the agents collaborate in real-time
6. Download your comprehensive research report

### Example Topics

- "Top 3 F1 drivers of all time"
- "Latest developments in quantum computing"
- "Benefits of Kubernetes for AI workloads"
- "Impact of microservices on system design"

## ğŸ“ Repository Structure

```
multi-agent-research-system/
â”‚
â”œâ”€â”€ agents/                      # Agent implementations
â”‚   â”œâ”€â”€ *_service.py            # REST API versions
â”‚   â”œâ”€â”€ *_a2a.py                # A2A Protocol versions
â”‚   â”œâ”€â”€ base_agent.py           # REST base class
â”‚   â””â”€â”€ a2a_base_agent.py       # A2A base class
â”‚
â”œâ”€â”€ coordinator/                 # Workflow orchestrators
â”‚   â”œâ”€â”€ coordinator_service.py  # REST version
â”‚   â””â”€â”€ coordinator_a2a.py      # A2A version
â”‚
â”œâ”€â”€ frontend/                    # User interface
â”‚   â””â”€â”€ streamlit_frontend.py   # Streamlit web UI
â”‚
â”œâ”€â”€ shared/                      # Common code
â”‚   â”œâ”€â”€ shared_models.py        # REST models
â”‚   â””â”€â”€ a2a_models.py           # A2A protocol models
â”‚
â”œâ”€â”€ kubernetes/                  # Deployment manifests
â”‚   â”œâ”€â”€ deployments.yaml        # REST version
â”‚   â””â”€â”€ deployments-a2a.yaml    # A2A version
â”‚
â”œâ”€â”€ docker/                      # Container definitions
â”‚   â”œâ”€â”€ Dockerfile.agent        # Agent services
â”‚   â”œâ”€â”€ Dockerfile.coordinator  # REST coordinator
â”‚   â”œâ”€â”€ Dockerfile.coordinator-a2a  # A2A coordinator
â”‚   â””â”€â”€ Dockerfile.streamlit    # Frontend
â”‚
â”œâ”€â”€ requirements/                # Python dependencies
â”‚   â”œâ”€â”€ requirements-agent.txt
â”‚   â”œâ”€â”€ requirements-coordinator.txt
â”‚   â””â”€â”€ requirements-streamlit.txt
â”‚
â”œâ”€â”€ scripts/                     # Automation scripts
â”‚   â”œâ”€â”€ deploy-to-kind.sh       # Deploy REST version
â”‚   â”œâ”€â”€ deploy-a2a-to-kind.sh   # Deploy A2A version (Kind)
â”‚   â”œâ”€â”€ deploy-a2a-to-kubeadm.sh # Deploy A2A version (kubeadm)
â”‚   â”œâ”€â”€ cleanup.sh              # Cleanup/management
â”‚   â””â”€â”€ debug-connectivity.sh   # Troubleshooting
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ architecture.md         # Detailed architecture
â”‚   â”œâ”€â”€ REST-vs-A2A.md         # Version comparison
â”‚   â””â”€â”€ troubleshooting.md      # Common issues
â”‚
â””â”€â”€ examples/                    # Usage examples
    â”œâ”€â”€ custom-workflows/       # Custom agent workflows
    â””â”€â”€ integrations/           # Framework integrations
```

## ğŸ”„ Switching Between Versions

```bash
# Clean current deployment
./scripts/cleanup.sh  # Choose option 1

# Deploy REST version (Kind)
./scripts/deploy-to-kind.sh

# OR deploy A2A version (Kind)
./scripts/deploy-a2a-to-kind.sh

# OR deploy A2A version (kubeadm with local registry)
./scripts/deploy-a2a-to-kubeadm.sh
```

## ğŸ”„ Reusing Agents

Agents can be used in other applications! See [examples/](examples/) for:

- **FAQ Generator** - Auto-generate FAQs for any topic
- **Content Writer** - Create articles with AI assistance
- **Search Assistant** - Enhanced search with analysis
- **FastAPI Service** - Expose agents as REST APIs

Full guide: [docs/agent-reuse.md](docs/agent-reuse.md)

## ğŸ› ï¸ Development

### Scaling Agents

```bash
# Scale search agent for more concurrent searches
kubectl scale deployment/search-strategist --replicas=3

# Scale all agents
kubectl scale deployment/topic-refiner --replicas=2
```

### Monitoring

```bash
# View all pods
kubectl get pods

# Watch coordinator logs
kubectl logs -f deployment/coordinator

# Check agent capabilities (A2A version)
kubectl port-forward service/topic-refiner-service 8001:8001
curl http://localhost:8001/capabilities
```

## ğŸ§¹ Management

```bash
# Interactive cleanup menu
./scripts/cleanup.sh

# Options:
# 1. Delete all deployments
# 2. Delete everything including secrets
# 3. Scale to 0 (pause system)
# 4. Scale to 1 (resume system)
# 5. Restart all pods
```

## ğŸ“Š Resource Requirements

**Minimum (1 replica each):**
- Memory: ~6.5 GiB
- CPU: ~3.5 cores
- Storage: ~2 GiB

**Recommended (scaled):**
- Memory: ~14 GiB
- CPU: ~8 cores

## ğŸ›  Troubleshooting

```bash
# Debug connectivity
./scripts/debug-connectivity.sh

# Check pod status
kubectl get pods

# View logs
kubectl logs <pod-name>

# Describe pod
kubectl describe pod <pod-name>
```

See [docs/troubleshooting.md](docs/troubleshooting.md) for detailed solutions.

## ğŸ“š Documentation

- [Architecture Details](docs/architecture.md) - System design and data flow
- [REST vs A2A Comparison](docs/REST-vs-A2A.md) - Version differences
- [Troubleshooting](docs/troubleshooting.md) - Common issues and solutions
- [Agent Reusability](docs/agent-reuse.md) - Using agents in other apps

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspiration taken from [KodeCloud - LangGraph labs](https://learn.kodekloud.com/user/courses/youtube-labs-langgraph)
- Built with [LangChain](https://www.langchain.com/) and [Google Gemini](https://ai.google.dev/)
- UI powered by [Streamlit](https://streamlit.io/)
- Orchestrated with [Kubernetes](https://kubernetes.io/)
- Search via [DuckDuckGo](https://duckduckgo.com/)
- A2A Protocol by [Google](https://github.com/google/a2a)

---

**â­ If you find this project useful, please consider giving it a star!**